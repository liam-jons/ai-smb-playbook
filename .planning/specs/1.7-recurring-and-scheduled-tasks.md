# Spec 1.7 — Recurring & Scheduled Tasks

> **Phase 2 build agent:** Agent 3 — Skills, Governance, Brand sections
> **Track:** General

## Purpose

This section gives Phew! staff an honest, practical overview of what can and cannot be automated with Claude today. It addresses the "How to set up recurring/scheduled tasks" topic raised in the initial planning, directly referencing examples from the training (deal monitoring, website change detection). The section must set clear expectations — Claude does not have built-in scheduling or cron-like capabilities — while showing the patterns and workarounds that do exist, so Phew! can start building automations where the technology supports it and plan for what is coming.

## Source References

| File | Path | What to extract |
|------|------|-----------------|
| Training summary | `.planning/source-context/phew-training-ai-and-the-art-of-the-possible-summary.md` | References to automation, monitoring workflows, deal monitoring, and website change detection discussed during training. Extract the specific examples mentioned so the playbook can reference "the deal monitoring workflow we discussed in the training" naturally. |
| Initial thoughts | `.planning/source-context/phew-initial-thoughts-for-meeting-follow-up.md` | The recurring/scheduled tasks topic under General > Skills > Use cases: "How to setup recurring/scheduled tasks". This confirms the topic was specifically requested. |
| App tech stack | `.planning/research/app-tech-stack.md` | UI component decisions: shadcn/ui (Accordion, Card, Alert, Badge, Tabs), copy-to-clipboard hook, code block component with Shiki highlighting. |
| Frontend skills review | `.planning/research/frontend-skills-review.md` | Design guidelines, typography, colour, motion, accessibility, and the full Build Agent Checklist. |
| Handoff doc | `.planning/phew-follow-up-handoff.md` | Section 1.7 definition: "What's currently possible (and what isn't yet), patterns for automation: browser automation via CoWork, monitoring workflows, self-updating skills, reference to deal monitoring / website change detection from the training, honest about limitations." |

## Content Outline

### The Current State of Scheduling with Claude

An upfront, honest framing section that sets expectations before diving into patterns.

**Key talking points:**

- Claude does not have a built-in scheduler. There is no "run this every Monday at 9am" feature within Claude itself. This is one of the most commonly asked questions, and it is important to be clear about it.
- What Claude **can** do: execute complex, multi-step tasks when triggered — the triggering is the part that currently needs a human or an external system.
- What is coming: the landscape is evolving quickly. Anthropic and third-party tools are actively developing scheduling and trigger capabilities. This section describes the current state as of early 2026 and flags where things are likely to change.
- The practical implication: for now, think of Claude as a highly capable executor that you initiate, rather than a background service that runs on its own.

**Tone:** Reassuring, not apologetic. This is a fast-moving space and there are useful patterns available today — just not the fully autonomous scheduling some people expect.

### Patterns That Work Today

This is the core content of the section. Each pattern gets its own subsection with a clear explanation, a Phew!-relevant example, and where applicable a copyable prompt.

#### Pattern 1: Manual Trigger, Automated Execution

The simplest and most reliable pattern. You start the task manually (open Claude, paste a prompt or invoke a skill), and Claude handles the complex execution.

**How it works:**
- You create a detailed skill or prompt that defines the full workflow.
- When you want to run it, you open a new Claude session and trigger it — either by pasting the prompt or by asking Claude to use the relevant skill.
- Claude executes the multi-step task: gathering data, analysing, formatting output, and presenting results.

**Phew! example — Weekly training report:**
- A skill that reviews the LMS data export, summarises completion rates, flags any overdue training, and formats a report for the safeguarding partnership team.
- You would run this weekly by opening Claude, pointing it at the latest export, and asking it to generate the report.
- The intelligence is in the skill; your effort is limited to triggering it and providing the data.

**When to use this:** Any recurring task where the execution is complex but the trigger can be manual. This covers the majority of Phew!'s current use cases.

#### Pattern 2: Browser Automation via CoWork

CoWork (Anthropic's browser agent environment) can interact with web interfaces, fill forms, extract data, and navigate multi-step processes.

**How it works:**
- CoWork operates a browser session that Claude controls. When the browser is under AI control, the border displays an orange hue.
- You can instruct Claude to visit a website, log in (with credentials you provide), navigate to specific pages, extract data, and compile results.
- This is particularly useful for monitoring tasks where the data lives in a web interface rather than a file.

**Phew! example — Website accessibility monitoring:**
- A CoWork session that visits a set of client websites, runs a quick accessibility check (via the browser's built-in audit tools or a specific URL pattern), and compiles the results into a summary.
- Useful for Phew!'s "Accessibility as a Service" offering — regular checks on client sites.

**Phew! example — Deal/opportunity monitoring (from the training):**
- As discussed in the training session: a CoWork workflow that checks a pipeline tool or inbox for new opportunities, extracts key details, and formats them for review.
- Currently requires manual triggering, but the extraction and formatting logic can be fully automated within the session.

**When to use this:** When the data you need lives in a web application and there is no API or export. CoWork is the bridge between "I need to check this website regularly" and "Claude can read and process the information."

**Limitations to flag:**
- CoWork sessions are not persistent — they do not run in the background.
- Browser automation can break if the target website changes its layout.
- Credentials must be provided carefully (use Phew!'s existing password management practices).

#### Pattern 3: Self-Updating Skills

Skills can be designed to update their own content based on new information. This is not scheduling in the traditional sense, but it creates a pattern where running a skill produces an improved version of itself.

**How it works:**
- A skill includes instructions to review its own output, compare against previous runs (if stored), and update its parameters or templates.
- Each time you run the skill, it incorporates what it learnt from the last run.
- This creates a feedback loop: the skill gets better and more tailored over time.

**Phew! example — Client onboarding checklist:**
- A skill that walks through the steps for setting up a new LMS client. Each time it is used, the person running it can note any steps that were missing or wrong. The skill's final action is to update the checklist template based on that feedback.
- Over time, the onboarding process becomes more complete and accurate without anyone maintaining a separate document.

**When to use this:** For any process that benefits from incremental improvement. The skill is both the executor and the maintainer.

#### Pattern 4: External Trigger + Claude Execution

For teams with some technical capability, external scheduling tools can trigger Claude tasks.

**How it works:**
- An external system (cron job, CI/CD pipeline, task scheduler, or webhook) triggers a Claude Code session or API call at a set time.
- Claude receives the context and executes the defined workflow.
- Results can be written to files, sent via email, or posted to a channel.

**Phew! example — Automated code quality check:**
- A GitHub Actions workflow that runs nightly, invoking Claude Code to review recent commits against Phew!'s coding standards and generate a summary.
- This is a developer-pattern but included here because the concept applies: the schedule lives outside Claude, the intelligence lives inside Claude.

**When to use this:** When you need genuine scheduled execution (not just manual triggering). Requires some developer involvement to set up the external trigger. Cross-reference with the Developer track for implementation details.

**Note for Phew!:** This pattern is most relevant for the dev team (Andrew, Nick). For general users, Patterns 1–3 are the practical starting points.

### What's Not Yet Possible (Honest Limitations)

A clearly marked section that addresses the gaps directly. This builds trust — the playbook is not overselling.

**Currently not possible:**
- **Background monitoring:** Claude cannot watch a website, inbox, or data source continuously and alert you when something changes. Each session is initiated by a user or an external trigger.
- **True cron scheduling within Claude:** There is no "schedule this task" button in Claude Desktop or claude.ai. You cannot tell Claude "run this every Friday at 3pm" and have it happen automatically.
- **Persistent sessions:** Claude sessions are stateful while open but do not persist across restarts. You cannot leave a monitoring task "running" overnight.
- **Cross-session memory for recurring tasks:** While Claude has a memory feature, it does not automatically remember that you ran a specific task last week and that it should run again this week. You need to trigger it.

**What is likely coming:**
- Anthropic and third-party developers are actively building scheduling and trigger capabilities. The trajectory is clearly towards more autonomous operation.
- CoWork and similar agent environments are evolving towards persistent background tasks.
- API-based integrations are becoming more accessible, which will enable external schedulers to trigger Claude tasks more easily.
- The best preparation: build your workflows as skills and prompts now, so they are ready to plug into scheduling infrastructure as it becomes available.

**Key message:** The limitation is in the triggering, not the execution. Claude can already do the hard part (analysing, summarising, formatting, decision-making). Building your workflows now means you will be ready to automate the trigger as soon as the tooling catches up.

### Getting Started: Recommended First Steps for Phew!

A practical, actionable closing section that tells Phew! staff exactly where to begin.

**Step 1: Identify your recurring tasks**
- What do you do weekly, monthly, or after specific events that involves gathering data, summarising, or formatting?
- Examples from Phew!: training completion reports, client site accessibility checks, proposal formatting, audit report generation.

**Step 2: Build a skill for each one**
- Write the workflow as a Claude skill (see Section 1.4 for how skills work, see the Starter Kit for examples).
- Test it manually a few times and refine.

**Step 3: Create a "run book" prompt**
- For each recurring task, write a trigger prompt that you paste into Claude to kick off the workflow.
- Store these prompts somewhere accessible to the team (a shared document, a Slack channel, or the Skills system itself).

**Step 4: Review monthly**
- Check whether new capabilities have been released that would allow you to automate the trigger step.
- The AI landscape moves quickly — what requires manual triggering today may be fully schedulable in three months.

## Interaction Design

### Components Used

| Component | Source | Usage |
|-----------|--------|-------|
| `Card` | shadcn/ui | Each automation pattern presented in a Card with header, description, and example |
| `Alert` | shadcn/ui | The "What's Not Yet Possible" section uses a clearly-styled Alert (informational, not error — to set the right tone) |
| `Badge` | shadcn/ui | Labels for pattern difficulty/applicability: "Everyone", "With dev support", "Developers" |
| `Accordion` | shadcn/ui | The four patterns could be presented in an accordion for mobile, or as full Cards on desktop |
| `Button` | shadcn/ui | Copy buttons on prompts, "Learn more" links to related sections |
| `Separator` | shadcn/ui | Between major content blocks |
| `Collapsible` | shadcn/ui | "What's likely coming" subsection within limitations — collapsible since it is forward-looking and speculative |

### Layout

- **Mobile (< 640px):** Single column. Patterns stack vertically. Use Accordion for the four patterns to conserve vertical space — user expands the one they want to read.
- **Tablet (640px–1023px):** Single column, but patterns displayed as full Cards (no accordion). More breathing room.
- **Desktop (1024px+):** Single column for readability (body text at 65ch max width). Patterns as Cards. The "Getting Started" section could use a numbered-step layout with left-aligned step numbers and right-aligned content.

### Pattern Cards Design

Each pattern Card should have:
1. **Header area:** Pattern name + Badge indicating audience (e.g., "Everyone" in a neutral badge, "With dev support" in a secondary badge).
2. **Description:** 2–3 paragraphs explaining the pattern.
3. **Phew! Example:** A clearly marked example block (use a subtle background tint or left border, not a nested Card). Include the specific Phew! example.
4. **Copyable prompt (where applicable):** A code/prompt block with the copy-to-clipboard button.
5. **"When to use this":** A brief summary line at the bottom.

### Animation / Motion

- **Accordion expand/collapse (mobile):** Use shadcn's built-in Radix animation. Supplement with Motion `layout` prop only if variable-height content causes layout jank. Duration: 300–500ms. Easing: ease-out (`cubic-bezier(0.16, 1, 0.3, 1)`).
- **Card hover (desktop):** Tailwind `transition-shadow duration-200` only. No Motion.
- **Collapsible expand (What's likely coming):** CSS transition via shadcn. 200–300ms.
- **Respect `prefers-reduced-motion`:** Fall back to instant state changes.

### Cross-References

This section should link to:
- **Section 1.4** (Skills, Extensions & Decision Tree) — for understanding how to build skills referenced in patterns.
- **Section 1.3** (Session Management) — for understanding why sessions are not persistent.
- **Developer track** — a callout for dev team members that Pattern 4 (External Trigger) is expanded in the Developer track.

Use inline text links for these references, not buttons or cards. Keep cross-references lightweight.

## Copyable Content

All prompts below must have the copy-to-clipboard button (using the `CopyButton` component with the `useCopyToClipboard` hook).

### Prompt 1: Weekly Report Generation Skill Trigger

```
I'd like you to generate a weekly training report. Please:

1. Review the training data I'm about to provide
2. Summarise completion rates by team/department
3. Flag any overdue or incomplete mandatory training
4. Highlight trends compared to the previous period (if I provide it)
5. Format the output as a brief report suitable for sharing with the safeguarding partnership team

Use UK English throughout. Keep the tone professional but accessible.

Here's the data:
[paste your training data export here]
```

### Prompt 2: Website Change Detection Workflow

```
I need you to check a website for changes. Please:

1. I'll provide the current content of the page (or a screenshot)
2. Compare it against the reference version I'll also provide
3. List all significant changes (content additions, removals, or modifications)
4. Flag any changes that might affect accessibility compliance
5. Summarise the changes in a brief report

Current page content:
[paste current content or describe what you see]

Reference version (from last check):
[paste previous content or describe the baseline]
```

### Prompt 3: Self-Updating Skill Template

```
You are a [task name] skill. Your job is to [describe the task].

## Current Parameters
- [Parameter 1]: [value]
- [Parameter 2]: [value]
- [Last updated]: [date]

## Workflow
1. [Step 1]
2. [Step 2]
3. [Step 3]

## Self-Update Instructions
After completing the task, ask the user:
- "Were any steps missing or unclear?"
- "Should any parameters be updated based on this run?"

If the user provides feedback, output an updated version of this entire skill with the changes incorporated and the "Last updated" date set to today.
```

### Prompt 4: Recurring Task Identifier

```
I'd like to identify tasks in my team's workflow that could benefit from AI automation. Please help me think through this by asking me questions about:

1. What tasks do I or my team do on a regular schedule (daily, weekly, monthly)?
2. For each task: what data goes in, what output comes out, and who uses the output?
3. Which of these tasks involve gathering information from multiple sources?
4. Which involve formatting or summarising information?
5. Which are time-consuming but follow a predictable pattern?

After we've identified the tasks, help me prioritise them by:
- How much time they currently take
- How predictable/structured the workflow is (more structured = easier to automate)
- How critical accuracy is (high-stakes tasks may need more human oversight)

Let's start with the first question — what recurring tasks does your team handle?
```

## Two-Track Considerations

This section is **General track only**. However, it contains one pattern (Pattern 4: External Trigger + Claude Execution) that bridges into developer territory.

**How to handle the bridge:**
- Include Pattern 4 in this section but mark it clearly with a "With dev support" Badge.
- Keep the explanation at a conceptual level — what it achieves, not how to implement it.
- Include a clear cross-reference: "For implementation details on setting up external triggers, see the Developer track."
- Do not include code examples for Pattern 4 in this section. The Developer track would be the appropriate place for CI/CD pipeline examples, API call patterns, etc.

**General audience assumptions:**
- Users access Claude via claude.ai or Claude Desktop.
- They can create and use skills but do not write code.
- They can use CoWork for browser automation if guided.
- They do not manage CI/CD pipelines or cron jobs.

## Acceptance Criteria

1. The section opens with an honest, clear statement that Claude does not have built-in scheduling capabilities — no buried caveats or misleading implications.
2. At least four distinct automation patterns are presented, each with a clear explanation, a Phew!-relevant example, and guidance on when to use it.
3. Each pattern is labelled with its audience applicability (e.g., "Everyone", "With dev support") using Badge components.
4. The "What's Not Yet Possible" section is clearly delineated (using an Alert component) and covers: background monitoring, built-in scheduling, persistent sessions, and cross-session memory for recurring tasks.
5. The "What's Likely Coming" content is in a Collapsible, since it is forward-looking and may change.
6. At least three copyable prompts are provided, each with a functioning copy-to-clipboard button.
7. All copyable prompts use UK English, reference Phew!-relevant scenarios, and are immediately usable (not placeholders).
8. Cross-references to Sections 1.3 (Session Management) and 1.4 (Skills & Decision Tree) are included as inline text links.
9. A cross-reference to the Developer track is included for Pattern 4 (External Trigger).
10. The "Getting Started" section provides 3–4 actionable steps that Phew! staff can follow immediately.
11. The layout is responsive: Accordion for patterns on mobile (< 640px), Cards on tablet/desktop.
12. All body text is at least 16px (1rem) with a maximum line length of 65ch.
13. Keyboard navigation works throughout: Tab moves between interactive elements, Enter/Space activates accordions and buttons, focus indicators are visible.
14. The page respects `prefers-reduced-motion` — accordion and collapsible animations fall back to instant state changes.
15. UK English is used throughout all copy (spelling, grammar, date formats DD/MM/YYYY).
16. Semantic HTML is used: proper heading hierarchy, landmark elements, ARIA attributes on accordions and collapsibles.
17. Touch targets on all interactive elements are at least 44px.
18. No "AI slop" design patterns: no identical card grids, no gradient text, no glassmorphism.
19. Content is defined as typed TypeScript objects (not hard-coded JSX) so the data layer is separate from the presentation.
20. The section does not overstate what Claude can do — every capability claim is accurate as of early 2026.

## Build Agent Checklist

### Frontend Quality Checklist

**Typography**
- [ ] Body text >= 16px (1rem), using rem units
- [ ] Max line length: 65ch for body text
- [ ] Fluid type (clamp) on headings; fixed sizes on UI controls
- [ ] Font stacks include size-adjusted fallback
- [ ] No generic fonts (Inter, Roboto, etc.) unless explicitly specified

**Colour & Theming**
- [ ] All custom colours defined in OKLCH via CSS variables
- [ ] Neutrals tinted towards brand hue (not pure grey)
- [ ] No pure black (#000) or pure white (#fff)
- [ ] Dark mode tested and functional (if applicable to section)
- [ ] All text meets WCAG AA contrast (4.5:1 body, 3:1 large/UI)

**Layout & Spacing**
- [ ] Spacing values from the 4pt grid (4, 8, 12, 16, 24, 32, 48, 64, 96)
- [ ] Visual hierarchy uses 2+ dimensions (size, weight, colour, space)
- [ ] No nested cards
- [ ] No identical repeating card grids

**Motion & Animation**
- [ ] Only `transform` and `opacity` animated (no width/height/top/left)
- [ ] Timing follows 100/300/500 rule
- [ ] Easing uses exponential curves (not default `ease` or bounce)
- [ ] `prefers-reduced-motion` handled (crossfade fallback or disable)
- [ ] Exit animations faster than entrances
- [ ] Motion used via Tailwind transitions where CSS suffices; Motion library only for layout/enter/exit

**Interaction**
- [ ] All 8 interactive states designed (default, hover, focus, active, disabled, loading, error, success)
- [ ] `:focus-visible` ring on all interactive elements (2-3px, offset, 3:1 contrast)
- [ ] Touch targets >= 44px
- [ ] Copy-to-clipboard on every prompt/template/code block
- [ ] Skeleton screens for loading states (not generic spinners)

**Accessibility**
- [ ] Semantic HTML (headings, landmarks, labels)
- [ ] Skip link present
- [ ] Keyboard navigation tested (Tab, Enter, Escape, Arrows)
- [ ] `aria-expanded`, `aria-controls` on accordions/collapsibles
- [ ] `aria-label` on icon-only buttons
- [ ] Images have `alt` text (or `alt=""` for decorative)
- [ ] Never `outline: none` without `:focus-visible` replacement

**Performance**
- [ ] No barrel file imports (direct imports from source)
- [ ] Shiki lazy-loaded (not in initial bundle)
- [ ] Derived state computed during render (no useEffect for derived values)
- [ ] `content-visibility: auto` on long scrollable content
- [ ] Passive event listeners on scroll/touch handlers
- [ ] Static JSX hoisted outside components where possible

**Responsive**
- [ ] Mobile-first (base styles for mobile, min-width queries for larger)
- [ ] Tested at 320px, 640px, 768px, 1024px widths
- [ ] No critical functionality hidden on mobile
- [ ] Hover-dependent features have touch alternatives
- [ ] Safe area insets handled for mobile

**UX Writing & Content**
- [ ] UK English throughout (spelling, grammar, currency, date format)
- [ ] Button labels use verb + object pattern
- [ ] Error messages answer: what, why, how to fix
- [ ] Consistent terminology (no synonyms for the same action)
- [ ] Empty states are actionable, not just "Nothing here"

**Code Quality**
- [ ] Tailwind utility classes only (no CSS modules or styled-components)
- [ ] `cn()` utility for conditional class merging
- [ ] `@/` path alias for all imports
- [ ] Components composed from shadcn primitives (not mega-components)
- [ ] Content defined as typed TS objects, not hard-coded JSX
